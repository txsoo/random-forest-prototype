# Hit Identificator - PrÃ©diction d'ActivitÃ© Biologique par Machine Learning (HEI3)

## ğŸ“‹ Vue d'ensemble

Ce dÃ©pÃ´t sâ€™inscrit dans le cadre du projet B-Live HEI.

**Aragorn** est un pipeline de machine learning dÃ©diÃ© Ã  lâ€™identification de hits en drug discovery. Le projet utilise des donnÃ©es bioactives issues de ChEMBL afin dâ€™entraÃ®ner un modÃ¨le Random Forest capable de prÃ©dire lâ€™activitÃ© biologique de molÃ©cules candidates contre une cible thÃ©rapeutique.
La cible par dÃ©faut est lâ€™enzyme COX-2 (Cyclooxygenase-2).

### ğŸ¯ Objectif principal
Automatiser la priorisation de molÃ©cules candidates lors du criblage virtuel en prÃ©disant leur activitÃ© biologique (actif/inactif) Ã  partir de leur structure chimique.

### âš¡ Performances obtenues (COX-2)
- **Dataset** : 1073 molÃ©cules curÃ©es (683 actifs / 390 inactifs)
- **ModÃ¨le** : Random Forest calibrÃ© (400 arbres, 1625 features)
- **PR-AUC** : **0.869** (excellent pour classes dÃ©sÃ©quilibrÃ©es)
- **ROC-AUC** : **0.773** | **PrÃ©cision** : **83.3%** | **Recall** : **75.7%**
- **Calibration** : Isotonic (probabilitÃ©s fiables)
- **Temps d'entraÃ®nement** : ~2-3 minutes

---

## ğŸ¯ UtilitÃ© du projet

### Contexte scientifique
En drug discovery, identifier des "hits" (molÃ©cules actives prometteuses) parmi des millions de candidats est un dÃ©fi coÃ»teux et chronophage. Ce projet permet de :

- **RÃ©duire les coÃ»ts** : Criblage virtuel avant les tests expÃ©rimentaux
- **AccÃ©lÃ©rer la dÃ©couverte** : Priorisation automatique des molÃ©cules candidates
- **Optimiser la chimie mÃ©dicinale** : Guidage des efforts de synthÃ¨se vers les composÃ©s les plus prometteurs
- **PrÃ©dire l'activitÃ©** : Estimation quantitative (pIC50) et qualitative (actif/inactif)

### Applications pratiques
1. **Criblage virtuel** : Filtrer rapidement de grandes bibliothÃ¨ques chimiques
2. **Lead optimization** : Ã‰valuer des analogues avant synthÃ¨se
3. **Analyse SAR** : Comprendre les relations structure-activitÃ©
4. **Domaine d'applicabilitÃ©** : Estimer la fiabilitÃ© des prÃ©dictions

---

## ğŸ”¬ Comment fonctionne le projet

### Architecture du pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   1. PRÃ‰PARATION DONNÃ‰ES                     â”‚
â”‚            chembl_dataset_preparation.py                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ TÃ©lÃ©chargement ChEMBL (API)                              â”‚
â”‚  â€¢ Filtrage qualitÃ© (IC50, assay confidence â‰¥8)             â”‚
â”‚  â€¢ Standardisation chimique (RDKit)                         â”‚
â”‚  â€¢ DÃ©duplication (InChIKey)                                 â”‚
â”‚  â€¢ Filtres qualitÃ© (PAINS, Brenk, NIH)                      â”‚
â”‚  â€¢ Calcul descripteurs molÃ©culaires                         â”‚
â”‚  â€¢ CrÃ©ation splits (scaffold, cluster)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   2. ENTRAÃNEMENT MODÃˆLE                     â”‚
â”‚              random_forest_training.py                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Chargement dataset (X_features.npy, y_labels.npy)       â”‚
â”‚  â€¢ Split scaffold (Ã©vite data leakage)                      â”‚
â”‚  â€¢ Optimisation hyperparamÃ¨tres (GridSearchCV)              â”‚
â”‚  â€¢ EntraÃ®nement Random Forest                               â”‚
â”‚  â€¢ Calibration probabilitÃ©s (isotonic)                      â”‚
â”‚  â€¢ Ã‰valuation (PR-AUC, ROC-AUC, MCC, EF, BEDROC)           â”‚
â”‚  â€¢ Export modÃ¨le (.joblib, .onnx)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   3. PRÃ‰DICTION & ANALYSE                    â”‚
â”‚                  (Interface utilisateur)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Chargement modÃ¨le                                        â”‚
â”‚  â€¢ Calcul descripteurs nouvelles molÃ©cules                  â”‚
â”‚  â€¢ PrÃ©diction activitÃ© + probabilitÃ©s calibrÃ©es             â”‚
â”‚  â€¢ Estimation domaine d'applicabilitÃ©                       â”‚
â”‚  â€¢ InterprÃ©tation (feature importance)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Descripteurs molÃ©culaires

Le modÃ¨le utilise une combinaison de descripteurs pour reprÃ©senter les molÃ©cules :

| Type | Description | Dimension |
|------|-------------|-----------|
| **Morgan Fingerprints (ECFP4)** | Empreintes circulaires (rayon=2) | 2048 bits |
| **Poids molÃ©culaire** | MW (Da) | 1 |
| **LogP** | Lipophilie | 1 |
| **Donneurs H** | HBD | 1 |
| **Accepteurs H** | HBA | 1 |
| **Liaisons rotables** | FlexibilitÃ© | 1 |
| **TPSA** | Surface polaire topologique | 1 |

**Total : ~2054 features** aprÃ¨s filtrage des bits constants.

### MÃ©triques d'Ã©valuation

Le modÃ¨le est Ã©valuÃ© selon plusieurs mÃ©triques adaptÃ©es au criblage molÃ©culaire :

- **PR-AUC** (Average Precision) : Performance sur classes dÃ©sÃ©quilibrÃ©es
- **ROC-AUC** : CapacitÃ© de discrimination globale
- **EF@1%/5%** (Enrichment Factor) : Enrichissement dans le top hits
- **Top-50/100 Precision** : PrÃ©cision sur les meilleurs candidats
- **BEDROC** (Î±=20) : MÃ©trique chimique early recognition
- **MCC** (Matthews Correlation Coefficient) : QualitÃ© globale du classifieur

### Gestion du dÃ©sÃ©quilibre de classes

- **class_weight='balanced'** : PÃ©nalisation automatique des classes majoritaires
- **Calibration isotonic** : ProbabilitÃ©s fiables mÃªme avec dÃ©sÃ©quilibre
- **Optimisation sur PR-AUC** : MÃ©trique adaptÃ©e aux classes rares
- **Scaffold split** : Ã‰vite le sur-apprentissage sur scaffolds communs

---

## ğŸš€ Quick Start

### Installation rapide et premiÃ¨re utilisation

```bash
# 1. CrÃ©er l'environnement conda
conda create -n Aragorn python=3.9
conda activate Aragorn

# 2. Installer RDKit
conda install -c conda-forge rdkit=2023.3.2 -y

# 3. Installer les dÃ©pendances
pip install -r requirements.txt

# 4. GÃ©nÃ©rer le dataset ChEMBL (COX-2)
$env:LOCK_B_1073="1"
python chembl_dataset_preparation.py
# DurÃ©e: ~15-20 minutes â†’ gÃ©nÃ¨re data/ (~14 MB)

# 5. EntraÃ®ner le modÃ¨le
python random_forest_training.py
# DurÃ©e: ~2-3 minutes â†’ gÃ©nÃ¨re models/ (~12.3 MB)

# 6. Consulter les rÃ©sultats
cat models/metrics.json
# PR-AUC: 0.869 | ROC-AUC: 0.773
```

---

## ğŸ› ï¸ Installation dÃ©taillÃ©e

### PrÃ©requis

- Python 3.9 (testÃ© et validÃ©)
- Conda (recommandÃ© pour RDKit)
- ~2 GB d'espace disque
- Connexion internet (tÃ©lÃ©chargement ChEMBL)

### Versions des dÃ©pendances (testÃ©es)

```
Python: 3.9+
pandas: 2.0.3
numpy: 1.24.3
scikit-learn: 1.3.0
rdkit: 2023.03.2
chembl-webresource-client: 0.10.8
matplotlib: 3.7.2
```

### Ã‰tapes d'installation

1. **Cloner le dÃ©pÃ´t**
```bash
cd Desktop
git clone <url-du-depot> Aragorn
cd Aragorn
```

2. **CrÃ©er l'environnement conda**
```bash
conda create -n Aragorn python=3.9
conda activate Aragorn
```

3. **Installer RDKit**
```bash
conda install -c conda-forge rdkit=2023.3.2 -y
```

4. **Installer les dÃ©pendances Python**
```bash
pip install -r requirements.txt
```

### VÃ©rification de l'installation

```bash
python -c "from rdkit import Chem; import chembl_webresource_client; print('Installation OK')"
```

---

## ğŸ“– Utilisation

### 1. PrÃ©paration du dataset

**Script** : `chembl_dataset_preparation.py`

```bash
# Activer l'environnement
conda activate Aragorn

# GÃ©nÃ©rer le dataset (avec verrou pour sÃ©curitÃ©)
$env:LOCK_B_1073="1"
python chembl_dataset_preparation.py
```

**ParamÃ¨tres modifiables** (dans le script) :
- `target_chembl_id` : Cible ChEMBL (dÃ©faut: "CHEMBL279" = COX-2)
- `limit` : Nombre max de composÃ©s (dÃ©faut: 5000)
- `n_bits` : Taille des fingerprints (dÃ©faut: 2048)
- `replicate_std_threshold` : Seuil d'exclusion rÃ©plicats (dÃ©faut: 0.5)

**Sorties gÃ©nÃ©rÃ©es** :
```
data/
â”œâ”€â”€ X_features.npy              # Matrice de features (1073 x 1625) - 6.97 MB
â”œâ”€â”€ y_labels.npy                # Labels binaires (actif/inactif) - 4.4 KB
â”œâ”€â”€ y_reg.npy                   # Valeurs pIC50 continues - 8.7 KB
â”œâ”€â”€ y_labels_3class.npy         # Classification 3 classes - 8.7 KB
â”œâ”€â”€ dataset_info.pkl            # MÃ©tadonnÃ©es complÃ¨tes - 288 KB
â”œâ”€â”€ chembl_dataset_full.parquet # Dataset complet (format Parquet) - 1.49 MB
â”œâ”€â”€ chembl_dataset_full.csv     # Dataset complet (format CSV) - 4.63 MB
â”œâ”€â”€ duplicates_report.csv       # Rapport de dÃ©duplication - 179 KB
â”œâ”€â”€ splits/
â”‚   â”œâ”€â”€ scaffold_split.json     # Split par scaffolds - avec hash
â”‚   â”œâ”€â”€ cluster_split_t06.json  # Split par clusters (T=0.6)
â”‚   â””â”€â”€ cluster_split_t07.json  # Split par clusters (T=0.7)
â”œâ”€â”€ ad_nn_similarity.npy        # SimilaritÃ©s AD (215 valeurs) - 1.8 KB
â””â”€â”€ ad_stats.json               # Statistiques AD - 187 bytes
```

**Temps d'exÃ©cution** : ~10-30 minutes (selon limit et rÃ©seau)

---

### 2. EntraÃ®nement du modÃ¨le

**Script** : `random_forest_training.py`

```bash
# EntraÃ®nement avec paramÃ¨tres par dÃ©faut
python random_forest_training.py
```

**Options avancÃ©es** :

Pour activer le tuning d'hyperparamÃ¨tres (plus long, ~30-60 min) :
```python
# Dans random_forest_training.py, dÃ©commenter lignes 508-512
summary = trainer.tune_hyperparams(X_tr, y_tr, groups=train_groups)
params = summary["best_params"]
```

**Sorties gÃ©nÃ©rÃ©es** :
```
models/
â”œâ”€â”€ random_forest.joblib        # ModÃ¨le entraÃ®nÃ© (calibrÃ©) - 12.2 MB
â”œâ”€â”€ metrics.json                # MÃ©triques complÃ¨tes + mÃ©tadonnÃ©es - 4.6 KB
â””â”€â”€ plots/
    â””â”€â”€ pr_curve.png            # Courbe Precision-Recall - 47.7 KB
```

**MÃ©triques sauvegardÃ©es dans metrics.json** :
- ROC-AUC: 0.773, PR-AUC: 0.869
- Accuracy: 0.721, F1: 0.793, MCC: 0.372, Balanced Accuracy: 0.696
- Confusion matrix (test) : [[40, 23], [37, 115]]
- Seuils : optimal (MCC=0.429) et par dÃ©faut (0.5)
- Class balance train/calibration/test
- OOB score: 0.789
- Calibration isotonic utilisÃ©e (172 Ã©chantillons)
- Dataset hash pour traÃ§abilitÃ©

---

### 3. PrÃ©diction sur nouvelles molÃ©cules

**Exemple d'utilisation** (crÃ©er un script `predict.py`) :

```python
import numpy as np
import pandas as pd
from joblib import load
from rdkit import Chem
from rdkit.Chem.rdMolDescriptors import GetMorganFingerprintAsBitVect
from rdkit.Chem import Descriptors
import pickle

# Charger le modÃ¨le
model = load('models/random_forest.joblib')

# Charger les mÃ©tadonnÃ©es pour normalisation
with open('data/dataset_info.pkl', 'rb') as f:
    dataset_info = pickle.load(f)

# Fonction pour calculer les descripteurs
def compute_descriptors(smiles, n_bits=2048):
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        return None
    
    # Morgan fingerprint
    morgan_fp = GetMorganFingerprintAsBitVect(mol, radius=2, nBits=n_bits)
    morgan_array = np.zeros((n_bits,), dtype=np.uint8)
    from rdkit import DataStructs
    DataStructs.ConvertToNumpyArray(morgan_fp, morgan_array)
    
    # Descripteurs physico-chimiques
    mw = Descriptors.MolWt(mol)
    logp = Descriptors.MolLogP(mol)
    hbd = Descriptors.NumHDonors(mol)
    hba = Descriptors.NumHAcceptors(mol)
    rotatable_bonds = Descriptors.NumRotatableBonds(mol)
    tpsa = Descriptors.TPSA(mol)
    
    # Combiner (ordre important : correspondre Ã  l'entraÃ®nement)
    descriptors = np.concatenate([
        [mw, logp, hbd, hba, rotatable_bonds, tpsa],
        morgan_array
    ])
    
    return descriptors

# PrÃ©dire sur une nouvelle molÃ©cule
smiles_test = "CC(=O)Oc1ccccc1C(=O)O"  # Aspirine
descriptors = compute_descriptors(smiles_test)

if descriptors is not None:
    X_pred = descriptors.reshape(1, -1)
    
    # PrÃ©diction
    proba = model.predict_proba(X_pred)[0, 1]
    pred_class = model.predict(X_pred)[0]
    
    print(f"SMILES: {smiles_test}")
    print(f"ProbabilitÃ© d'Ãªtre actif: {proba:.3f}")
    print(f"Classe prÃ©dite: {'Actif' if pred_class == 1 else 'Inactif'}")
```

**Sortie exemple** :
```
SMILES: CC(=O)Oc1ccccc1C(=O)O
ProbabilitÃ© d'Ãªtre actif: 0.823
Classe prÃ©dite: Actif
```

---

### 4. Tests et validation

```bash
# ExÃ©cuter les tests unitaires
pytest -q

# Avec verbose
pytest -v
```

---

### 5. Inspection des rÃ©sultats

**Voir les statistiques du dataset :**
```bash
python -c "import pickle; info = pickle.load(open('data/dataset_info.pkl', 'rb')); print(f'MolÃ©cules: {info[\"n_samples\"]}'); print(f'Features: {info[\"n_features\"]}'); print(f'Actifs: {info[\"n_active_6p5\"]} ({info[\"activity_ratio_6p5\"]:.1%})'); print(f'Inactifs: {info[\"n_inactive_6p5\"]}')"
```

**Consulter les mÃ©triques du modÃ¨le :**
```bash
python -c "import json; m = json.load(open('models/metrics.json')); print(f'PR-AUC: {m[\"average_precision\"]:.3f}'); print(f'ROC-AUC: {m[\"roc_auc\"]:.3f}'); print(f'Accuracy: {m[\"accuracy\"]:.3f}'); print(f'F1: {m[\"f1\"]:.3f}'); print(f'Precision: {m[\"precision\"]:.3f}'); print(f'Recall: {m[\"recall\"]:.3f}')"
```

**VÃ©rifier le domaine d'applicabilitÃ© :**
```bash
python -c "import json; ad = json.load(open('data/ad_stats.json')); print(f'SimilaritÃ© NN moyenne: {ad[\"mean\"]:.3f} Â± {ad[\"std\"]:.3f}'); print(f'MÃ©diane: {ad[\"q50\"]:.3f}'); print(f'Q05-Q95: [{ad[\"q05\"]:.3f}, {ad[\"q95\"]:.3f}]')"
```

**Visualiser la courbe PR :**
```bash
start models/plots/pr_curve.png  # Windows
# ou
open models/plots/pr_curve.png   # macOS
```

---

## ğŸ“Š RÃ©sultats obtenus

### Performances rÃ©elles du modÃ¨le (COX-2)

| MÃ©trique | Valeur obtenue | Description |
|----------|----------------|-------------|
| **PR-AUC** | **0.869** â­ | Performance sur classes dÃ©sÃ©quilibrÃ©es |
| **ROC-AUC** | **0.773** | Discrimination globale |
| **Accuracy** | **0.721** | PrÃ©cision globale |
| **F1 Score** | **0.793** | Moyenne harmonique prÃ©cision/recall |
| **Precision** | **0.833** | Proportion de vrais positifs |
| **Recall** | **0.757** | Taux de dÃ©tection des actifs |
| **MCC** | **0.372** | CorrÃ©lation Matthews |
| **Balanced Accuracy** | **0.696** | Accuracy ajustÃ© au dÃ©sÃ©quilibre |
| **OOB Score** | **0.789** | Score Out-of-Bag du Random Forest |

#### Matrice de confusion (seuil par dÃ©faut 0.5)

```
                PrÃ©diction
              Inactif  Actif
RÃ©el Inactif      40     23     â†’ 63.5% spÃ©cificitÃ©
     Actif        37    115     â†’ 75.7% sensibilitÃ©
                                â†’ 83.3% prÃ©cision
```

**InterprÃ©tation** :
- Sur 215 molÃ©cules de test, **155 correctement classÃ©es** (72.1%)
- Sur 152 actifs rÃ©els, **115 dÃ©tectÃ©s** (recall = 75.7%)
- Sur 138 prÃ©dits actifs, **115 sont vrais positifs** (prÃ©cision = 83.3%)
- **Courbe PR** disponible dans `models/plots/pr_curve.png`

### Statistiques du dataset

- **Taille totale** : 1073 molÃ©cules (aprÃ¨s curation)
- **Distribution des classes** : 
  - Actifs (pIC50 â‰¥ 6.5) : 683 molÃ©cules (63.7%)
  - Inactifs (pIC50 < 6.5) : 390 molÃ©cules (36.3%)
- **Features** : 1625 descripteurs (aprÃ¨s filtrage bits constants)
  - Morgan fingerprints : ~1619 bits actifs
  - Descripteurs physico-chimiques : 6 features
- **Splits** : 
  - Train : 858 molÃ©cules (80%)
  - Test : 215 molÃ©cules (20%)
  - StratÃ©gie : Scaffold split (Bemis-Murcko)

### Domaine d'applicabilitÃ© (AD)

- **SimilaritÃ© NN moyenne** : 0.686 (Â±0.135)
- **MÃ©diane** : 0.692
- **Q05** : 0.438 | **Q95** : 0.879
- **Seuil recommandÃ©** : Tanimoto > 0.3

---

## ğŸ—‚ï¸ Structure du projet

```
Aragorn/
â”œâ”€â”€ README.md                           # Ce fichier
â”œâ”€â”€ requirements.txt                    # DÃ©pendances Python
â”œâ”€â”€ changelog.md                        # Historique des modifications
â”œâ”€â”€ DATA_CARD.md                        # Documentation du dataset
â”œâ”€â”€ chembl_dataset_preparation.py      # Pipeline de prÃ©paration (1315 lignes)
â”œâ”€â”€ random_forest_training.py          # EntraÃ®nement du modÃ¨le (540 lignes)
â”œâ”€â”€ chembl_dataset_preparation.logs    # Logs d'audit (69 KB)
â”œâ”€â”€ data/                              # DonnÃ©es gÃ©nÃ©rÃ©es (~14 MB total)
â”‚   â”œâ”€â”€ X_features.npy                 # 1073 x 1625 - 6.97 MB
â”‚   â”œâ”€â”€ y_labels.npy                   # Labels binaires - 4.4 KB
â”‚   â”œâ”€â”€ y_reg.npy                      # pIC50 continues - 8.7 KB
â”‚   â”œâ”€â”€ y_labels_3class.npy            # Classification 3 classes - 8.7 KB
â”‚   â”œâ”€â”€ dataset_info.pkl               # MÃ©tadonnÃ©es - 288 KB
â”‚   â”œâ”€â”€ chembl_dataset_full.parquet    # Dataset Parquet - 1.49 MB
â”‚   â”œâ”€â”€ chembl_dataset_full.csv        # Dataset CSV - 4.63 MB
â”‚   â”œâ”€â”€ duplicates_report.csv          # Rapport dÃ©duplication - 179 KB
â”‚   â”œâ”€â”€ ad_nn_similarity.npy           # SimilaritÃ©s AD - 1.8 KB
â”‚   â”œâ”€â”€ ad_stats.json                  # Statistiques AD - 187 bytes
â”‚   â””â”€â”€ splits/                        # StratÃ©gies de split
â”‚       â”œâ”€â”€ scaffold_split.json        # Bemis-Murcko scaffolds
â”‚       â”œâ”€â”€ cluster_split_t06.json     # Butina T=0.6
â”‚       â””â”€â”€ cluster_split_t07.json     # Butina T=0.7
â”œâ”€â”€ models/                            # ModÃ¨les entraÃ®nÃ©s (~12.3 MB)
â”‚   â”œâ”€â”€ random_forest.joblib           # ModÃ¨le calibrÃ© - 12.2 MB
â”‚   â”œâ”€â”€ metrics.json                   # MÃ©triques complÃ¨tes - 4.6 KB
â”‚   â””â”€â”€ plots/
â”‚       â””â”€â”€ pr_curve.png               # Courbe PR - 47.7 KB
â””â”€â”€ tests/                             # Tests unitaires
    â””â”€â”€ test_dataset_integrity.py      # Tests validation dataset
```

---

## ğŸ”§ Configuration avancÃ©e

### Changer la cible thÃ©rapeutique

Modifier dans `chembl_dataset_preparation.py` :

```python
# Exemple : Kinase EGFR (CHEMBL203)
preparator = ChEMBLDatasetPreparator(
    target_chembl_id="CHEMBL203",
    output_dir="data"
)
```

### Ajuster les critÃ¨res de qualitÃ©

```python
# Dans chembl_dataset_preparation.py
activities = self.activity_client.filter(
    target_chembl_id=self.target_chembl_id,
    standard_type="IC50",
    assay_confidence_score__gte=8,  # Modifier ici (7-9)
    # ... autres filtres
)
```

### Modifier le seuil d'activitÃ©

```python
# Dans clean_bioactivity_data()
df['active'] = (df['pic50'] >= 6.5).astype(int)  # Modifier le seuil
```

---

## ğŸ“š Ressources et rÃ©fÃ©rences

### Documentation externe

- **ChEMBL** : https://www.ebi.ac.uk/chembl/
- **RDKit** : https://www.rdkit.org/docs/
- **Scikit-learn** : https://scikit-learn.org/

### Articles scientifiques clÃ©s

1. **Fingerprints** : Rogers & Hahn (2010). "Extended-Connectivity Fingerprints"
2. **Scaffold splits** : Bemis & Murcko (1996). "The properties of known drugs"
3. **BEDROC** : Truchon & Bayly (2007). "Evaluating virtual screening methods"
4. **Applicability Domain** : Jaworska et al. (2005)

### MÃ©tadonnÃ©es des donnÃ©es

Consulter `DATA_CARD.md` pour :
- Provenance et filtres appliquÃ©s
- Protocole de standardisation chimique
- Statistiques dÃ©taillÃ©es du dataset
- Limitations et biais potentiels

---

## âš ï¸ Limitations et considÃ©rations

### Domaine d'applicabilitÃ©

Le modÃ¨le est fiable principalement pour :
- **MolÃ©cules similaires** au set d'entraÃ®nement (Tanimoto > 0.3)
- **Cible COX-2** (si autre cible : rÃ©-entraÃ®ner)
- **Domaine de pIC50** : 4-10 (~100 Î¼M Ã  0.1 nM)

**Ã‰viter les prÃ©dictions sur** :
- Peptides, biomolÃ©cules complexes
- MolÃ©cules inorganiques
- PAINS, composÃ©s rÃ©actifs
- MolÃ©cules trÃ¨s dissimilaires (Tanimoto < 0.3)

### Biais potentiels

- **Biais de publication** : ChEMBL contient principalement des molÃ©cules publiÃ©es
- **DÃ©sÃ©quilibre de classes** : Plus d'inactifs que d'actifs
- **VariabilitÃ© expÃ©rimentale** : DiffÃ©rents assays/labs
- **Scaffold coverage** : LimitÃ© aux chimies reprÃ©sentÃ©es dans ChEMBL

### Recommandations d'usage

1. **Toujours vÃ©rifier** le domaine d'applicabilitÃ© (similaritÃ© NN)
2. **Valider expÃ©rimentalement** les hits prÃ©dits
3. **Utiliser les probabilitÃ©s calibrÃ©es** (pas seulement la classe)
4. **InterprÃ©ter avec prudence** les prÃ©dictions limites (p ~ 0.5)
5. **Contextualiser** avec expertise chimie mÃ©dicinale

---

## ğŸ¤ Contribution et support

### Signaler un problÃ¨me

Utiliser l'onglet "Issues" sur GitHub avec :
- Description du problÃ¨me
- Code minimal reproductible
- Versions (Python, RDKit, etc.)
- Logs d'erreur

### Proposer des amÃ©liorations

1. Fork du dÃ©pÃ´t
2. CrÃ©er une branche (`feature/amelioration`)
3. Commit avec messages clairs
4. Pull request avec description

---

## ğŸ“ Licence

Ce projet est distribuÃ© sous licence MIT. Voir `LICENSE` pour plus de dÃ©tails.

---

## ğŸ™ Remerciements

- **ChEMBL** (EMBL-EBI) pour les donnÃ©es bioactives
- **RDKit** community pour la chÃ©moinformatique open-source
- **scikit-learn** pour les outils de machine learning

---

## ğŸ“§ Contact

Pour toute question ou collaboration :
- Email : [votre-email]
- GitHub : [votre-profil]

---

**DerniÃ¨re mise Ã  jour** : Novembre 2025  
**Version** : 1.0.0  
**Auteur** : Legrand Nathan

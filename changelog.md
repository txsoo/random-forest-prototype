# Hit Identificator - Journal de DÃ©veloppement

## 2025-09-19 - Fiabilisation entrainement et preparation

### Modifications
- Ajout d'un hash dataset ordonne et des listes `inchikeys`/`scaffold_labels` dans `chembl_dataset_preparation.py`; enrichissement des exports de splits avec `dataset_hash` et verifications renforcees (`verify_outputs`).
- `random_forest_training.py`: controle d'integrite dataset/split, seeds globaux, calibration isotonic via hold-out, `oob_score`, optimisation de seuil (MCC) et nouvelles metriques (balanced accuracy, MCC, class balance, snapshots).
- Sauvegarde dans `models/metrics.json` de l'instantane dataset, des versions, du contexte calibration/split avec lissage EMA des metriques numeriques.

### Impact
- Detection immediate des divergences entre donnees et splits et meilleure reproductibilite.
- Probabilites calibrees et seuil optimal -> meilleure articulation rappel/specifite selon les besoins produit.
- Historique des performances enrichi et contextualise pour suivre la stabilite du modele.

## ğŸ“… 2025-09-13 - Ã‰tape 1 : CÃ´tÃ© Scientifique (TERMINÃ‰E)

### âœ… RÃ©alisations

#### 1. Configuration du Projet
- **`requirements.txt`** crÃ©Ã© avec toutes les dÃ©pendances nÃ©cessaires :
  - `rdkit` pour la chÃ©moinformatique
  - `chembl-webresource-client` pour l'accÃ¨s aux donnÃ©es ChEMBL
  - `scikit-learn` pour le machine learning
  - `pandas`, `numpy` pour la manipulation de donnÃ©es
  - `matplotlib`, `seaborn` pour les visualisations
  - Support ONNX pour l'export de modÃ¨les

#### 2. PrÃ©paration du Dataset ChEMBL
- **`chembl_dataset_preparation.py`** dÃ©veloppÃ© avec classe `ChEMBLDatasetPreparator`
- **Cible sÃ©lectionnÃ©e** : CHEMBL279 (Cyclooxygenase-2 / COX-2)
- **Pipeline de donnÃ©es** :
  - TÃ©lÃ©chargement automatique depuis ChEMBL API
  - Filtrage des donnÃ©es IC50 (0.1 nM - 100 Î¼M)
  - Conversion en pIC50 et classification binaire (seuil = 6)
  - RÃ©cupÃ©ration des structures SMILES
  - Calcul des descripteurs molÃ©culaires

#### 3. Descripteurs MolÃ©culaires
- **Morgan Fingerprints** (ECFP4) : 2048 bits, rayon=2
- **Descripteurs RDKit** :
  - Poids molÃ©culaire
  - LogP (lipophilie)
  - Donneurs/accepteurs de liaisons H
  - Liaisons rotables
  - Surface polaire topologique (TPSA)

#### 4. ModÃ¨le Random Forest
- **`random_forest_training.py`** avec classe `RandomForestTrainer`
- **FonctionnalitÃ©s** :
  - PrÃ©processing automatique (split stratifiÃ©, normalisation)
  - Optimisation hyperparamÃ¨tres (Grid Search optionnel)
  - EntraÃ®nement Random Forest optimisÃ© pour chÃ©moinformatique
  - Ã‰valuation complÃ¨te (ROC AUC, Precision-Recall, Feature Importance)
  - Visualisations automatiques des performances

#### 5. Export et Sauvegarde
- **Formats multiples** :
  - Pickle (`.pkl`) - format natif Python
  - Joblib (`.joblib`) - optimisÃ© scikit-learn
  - ONNX (`.onnx`) - format portable inter-plateformes
- **MÃ©tadonnÃ©es** complÃ¨tes sauvegardÃ©es
- **Scaler** sauvegardÃ© pour normalisation cohÃ©rente

#### 6. Notebook de DÃ©monstration
- **`hit_identification_demo.ipynb`** crÃ©Ã©
- **Contenu** :
  - Pipeline complet interactif
  - Exploration et visualisation des donnÃ©es
  - Ã‰valuation dÃ©taillÃ©e du modÃ¨le
  - Test de prÃ©diction sur molÃ©cules connues (Aspirine, IbuprofÃ¨ne, etc.)
  - Analyse des features importantes

### ğŸ“Š RÃ©sultats Attendus
- **Dataset** : ~1500-2000 composÃ©s aprÃ¨s filtrage
- **Features** : ~2054 (2048 Morgan bits + 6 descripteurs)
- **Performance attendue** : ROC AUC > 0.8 pour COX-2
- **Classes** : Actifs (~20-30%) vs Inactifs

### ğŸ”§ Architecture Technique
```
chembl_dataset_preparation.py
â”œâ”€â”€ ChEMBLDatasetPreparator
â”‚   â”œâ”€â”€ download_bioactivity_data()
â”‚   â”œâ”€â”€ get_compound_data()
â”‚   â”œâ”€â”€ clean_bioactivity_data()
â”‚   â”œâ”€â”€ calculate_molecular_descriptors()
â”‚   â””â”€â”€ prepare_dataset()

random_forest_training.py
â”œâ”€â”€ RandomForestTrainer
â”‚   â”œâ”€â”€ load_dataset()
â”‚   â”œâ”€â”€ preprocess_data()
â”‚   â”œâ”€â”€ hyperparameter_tuning()
â”‚   â”œâ”€â”€ train_model()
â”‚   â”œâ”€â”€ evaluate_model()
â”‚   â””â”€â”€ save_model()
```

### ğŸ“ Structure des Fichiers
```
Hit identificator/
â”œâ”€â”€ chembl_dataset_preparation.py
â”œâ”€â”€ random_forest_training.py
â”œâ”€â”€ hit_identification_demo.ipynb
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ data/                          # GÃ©nÃ©rÃ© aprÃ¨s exÃ©cution
â”‚   â”œâ”€â”€ X_features.npy
â”‚   â”œâ”€â”€ y_labels.npy
â”‚   â”œâ”€â”€ dataset_info.pkl
â”‚   â””â”€â”€ chembl_dataset_full.csv
â””â”€â”€ models/                        # GÃ©nÃ©rÃ© aprÃ¨s entraÃ®nement
    â”œâ”€â”€ random_forest_model.pkl
    â”œâ”€â”€ random_forest_model.joblib
    â”œâ”€â”€ random_forest_model.onnx
    â”œâ”€â”€ scaler.pkl
    â”œâ”€â”€ model_metadata.pkl
    â””â”€â”€ plots/
        â”œâ”€â”€ evaluation_metrics.png
        â””â”€â”€ feature_importance.png
```

### ğŸ¯ Prochaines Ã‰tapes (Ã‰tape 2-4)
- [ ] **Infrastructure Compute** : Client Docker pour compute provider
- [ ] **Smart Contract** : Gestion dÃ©centralisÃ©e des jobs ML
- [ ] **Frontend** : Interface web React/Next.js
- [ ] **IntÃ©gration** : Pipeline complet bout-en-bout

---

## ğŸ“ Notes Techniques

### Choix de COX-2 comme Cible
- Cible bien documentÃ©e dans ChEMBL
- DonnÃ©es IC50 abondantes et de qualitÃ©
- Pertinence pharmaceutique (anti-inflammatoires)
- Bon Ã©quilibre actifs/inactifs pour classification

### Optimisations ImplÃ©mentÃ©es
- **Traitement par batch** pour Ã©viter timeouts API
- **Gestion d'erreurs** robuste pour SMILES invalides
- **Normalisation** des features pour amÃ©liorer performances
- **Validation croisÃ©e** pour sÃ©lection hyperparamÃ¨tres
- **Export multi-format** pour compatibilitÃ© maximale

### MÃ©triques de Performance
- **ROC AUC** : Mesure globale de discrimination
- **Precision-Recall** : Important pour classes dÃ©sÃ©quilibrÃ©es
- **Feature Importance** : InterprÃ©tabilitÃ© du modÃ¨le
- **Confusion Matrix** : Analyse dÃ©taillÃ©e des erreurs

---

## ğŸ› ï¸ 2025-09-14 - Correctif : Nettoyage robuste des bioactivitÃ©s

### ProblÃ¨me
- TypeError dans `chembl_dataset_preparation.py` > `clean_bioactivity_data()` lors du filtrage de `standard_value` (comparaison str/float).

### Cause racine
- `standard_value` contenait des chaÃ®nes et des unitÃ©s hÃ©tÃ©rogÃ¨nes (`standard_units`) non normalisÃ©es, entraÃ®nant des comparaisons directes str vs float.

### Correctif
- Conversion de `standard_value` en numÃ©rique via `pd.to_numeric(..., errors='coerce')`.
- Normalisation des `standard_units` (pm, nm, Âµm/um, mm, m).
- Calcul `pic50` en privilÃ©giant `pchembl_value` si disponible; sinon conversion en M via les unitÃ©s puis `-log10(M)`.
- Filtrage plausible par `pic50` dans [4, 10] (â‰ˆ 0.1 nM Ã  100 ÂµM).
- DÃ©finition de `active` par `pic50 >= 6`.

### Fichier impactÃ©
- `chembl_dataset_preparation.py` (mÃ©thode `clean_bioactivity_data`).

### RÃ©sultat
- Pipeline robuste aux types/units hÃ©tÃ©rogÃ¨nes; plus d'erreur de type et cohÃ©rence accrue du dataset.

---

## ğŸš€ 2025-09-14 - Mise Ã  niveau du pipeline ML (scaffold split, nested CV, rÃ©gression pIC50, calibration, AD, chembl_dataset_preparation.logs)

### Contexte
- Lâ€™exÃ©cution du pipeline se fait dans lâ€™environnement conda `Aragorn` et doit produire un audit complet.

### Changements clÃ©s
- Split train/test par scaffolds (Bemisâ€“Murcko) et nested cross-validation (GroupKFold).
- Objectif principal en rÃ©gression pIC50; classification binaire optionnelle au cutoff 6.5 et Ã©tiquettes 3 classes (â‰¤5.5, 5.5â€“6.5, â‰¥6.5).
- Consolidation par `canonical_smiles` (mÃ©diane pIC50), retrait des contradictions (std > 1.0), homogÃ©nÃ©isation de lâ€™espÃ¨ce (prioritÃ© Homo sapiens).
- Calibration des probabilitÃ©s (isotonic/sigmoid) et estimation dâ€™incertitude (Ã©cart-type des arbres RF + conformal prediction).
- Domaine dâ€™applicabilitÃ© via similaritÃ© Tanimoto au plus proche voisin du train.
- MÃ©triques de tri: PR-AUC, EF@1%, EF@5%, Top-k precision, BEDROC.
- Audit complet dans `chembl_dataset_preparation.logs` (versions, date dâ€™extraction, filtres appliquÃ©s, cutoff, hyperparamÃ¨tres, rÃ©sultats de validation, AD).

### Fichiers impactÃ©s
- `chembl_dataset_preparation.py` (refonte majeure du pipeline).
- `rules.md` (rappel environnement conda et mise Ã  jour des logs).

### Sorties gÃ©nÃ©rÃ©es
- `data/X_features.npy`, `data/y_labels.npy` (binaire 6.5), `data/y_reg.npy`, `data/y_labels_3class.npy`, `data/chembl_dataset_full.csv`, `data/dataset_info.pkl`.
- `chembl_dataset_preparation.logs` pour lâ€™audit horodatÃ© et dÃ©taillÃ©.

---

## ğŸ§¾ 2025-09-14 - Journal des modifications (CHANGELOG)

### Ajouts
- Curation ChEMBL robuste dans `chembl_dataset_preparation.py` :
  - Filtres dâ€™activitÃ© stricts : `standard_type=IC50`, `standard_relation='='`, `assay_type='B'`, `assay_confidence_score>=8`, `data_validity_comment is null`.
  - Journalisation des versions et capture de la release ChEMBL.
  - Standardisation chimique (rdMolStandardize), calcul dâ€™InChIKey et dÃ©duplication.
  - Filtres de qualitÃ© chimique (PAINS, Brenk, NIH, non organiques, mÃ©langes) avec comptages par raison.
  - AgrÃ©gation par InChIKey (mÃ©diane pIC50), seuil dâ€™Ã©cart-type des rÃ©plicats configurable (par dÃ©faut 0.5).
  - Curation des bits : suppression des colonnes Ã  variance nulle uniquement (bits constants 0/1) ; normalisation z uniquement des physico-chimiques.
  - Splits scaffold/cluster (Bemisâ€“Murcko, Butina@0.6/0.7) avec exports JSON et empreintes (hash).
  - Statistiques de domaine dâ€™applicabilitÃ© et export de la distribution (NN Tanimoto).
  - Export Parquet du dataset complet ; enrichissement des champs de `dataset_info.pkl`.
- Documentation : `DATA_CARD.md`, `rules_compliance.md`.
- Tests : `tests/test_dataset_integrity.py` couvrant les invariants du dataset.

### Modifications
- Fichier de log renommÃ© en `chembl_dataset_preparation.logs` et rÃ©fÃ©rencÃ© dans `logs.md`.
- `rules.md` conservÃ© comme rÃ©fÃ©rence ; instructions dâ€™exÃ©cution et journalisation alignÃ©es.

### Corrections
- Seuil binaire pIC50 â‰¥ 6.5 appliquÃ© de maniÃ¨re cohÃ©rente dans le pipeline et les logs.

---

*DerniÃ¨re mise Ã  jour : 2025-09-14 13:21*

---

## ğŸ§© 2025-09-14 - Correctifs pipeline dataset (alignement, curation bits, traÃ§abilitÃ©)

### ProblÃ¨mes rÃ©solus
- Splits JSON mal alignÃ©s avec X: recalcul des splits sur lâ€™index de `final_df` et assertions de couverture/overlap.
- 211 colonnes Morgan constantes conservÃ©es: purge via `VarianceThreshold(0.0)` et curation bits constants uniquement.
- RÃ©plicats bruyants: exclusion `pic50_std > 0.5` (paramÃ©trable) en agrÃ©gation InChIKey, avec journalisation des rejets.
- TraÃ§abilitÃ©: ajout `inchikey` et `standard_smiles` dans CSV/Parquet.
- MÃ©tadonnÃ©es: enrichies (`chembl_release`, `quality_rejections`, `bit_curation`, `versions`, `hashes` des splits, stats AD).
- DensitÃ© Morgan: maintenue dans [0.5%, 5%] aprÃ¨s VarianceThreshold(0.0); fallback Ã  4096 bits si densitÃ© > 5%.

---

## ğŸ”’ 2025-09-15 - Durcissement final du pipeline dataset (conformitÃ© rÃ¨gles)

### Changements clÃ©s
- Standardisation chimique stricte: `FragmentParent â†’ Normalize â†’ Reionize â†’ Canonicalize`; InChIKey via `from rdkit.Chem import inchi; inchi.MolToInchiKey(...)` uniquement.
- AgrÃ©gation par InChIKey avec exclusion des rÃ©plicats `pic50_std > 0.5` avant descripteurs et sauvegardes; logs des rejets.
- Curation des features: retrait des seules colonnes constantes; Z-score des 6 physico-chimiques; `VarianceThreshold(0.0)` juste avant sauvegarde de X; densitÃ© Morgan contrÃ´lÃ©e (fallback 4096 bits).
- Splits recalculÃ©s aprÃ¨s `final_df` avec assertions anti-fuite (overlap InChIKey/SMILES=0, couverture indices, max=n-1); export JSON + hash synchronisÃ© dans `dataset_info.pkl`.
- `dataset_info.pkl` enrichi: distributions `y_reg`, paramÃ¨tres d'empreinte, hashes des splits, stats AD.

### ExÃ©cution
- Environnement: `conda activate Aragorn`.
- Calibration scikit-learn: compat 1.3 (`CalibratedClassifierCV(estimator=..., cv='prefit')`) avec garde-fous de classes.

### Sorties
- Exports cohÃ©rents: `X_features.npy`, `y_labels.npy`, `y_reg.npy`, `y_labels_3class.npy`, `chembl_dataset_full.parquet/csv`, `splits/*.json`, `ad_stats.json`, `ad_nn_similarity.npy`.

*DerniÃ¨re mise Ã  jour : 2025-09-15 21:24*

## ğŸ“… 2025-09-16 - Alignement dataset (B=1073) â€” DÃ©cision et exÃ©cution (EN COURS)

### ğŸ” ProblÃ¨me
MÃ©lange dâ€™artefacts **A (1634)** et **B (1073)** dans `data/`, entraÃ®nant des incohÃ©rences entre X/Y/info/CSV et les splits/AD/duplicates.

### ğŸ“Œ Constats (Ã©tat actuel de `data/`)
**Jeu A (1634) â€” alignÃ© en interne**
- `X_features.npy` : `(1634, 2054)`
- `y_labels.npy` : `1634` *(taux dâ€™actifs 64.81 %)*
- `y_labels_3class.npy` : `{inactive=171, intermediate=404, active=1059}`
- `y_reg.npy` : `1634` *(moy=6.76, std=0.73, q05=5.57, q50=6.75, q95=8.00)*
- `dataset_info.pkl` : `n_samples=1634`, `n_features=2054` *(mÃ©tadonnÃ©es minimales)*
- `chembl_dataset_full.csv` : `(1634, 2059)` â†’ **sans** `inchikey`/`standard_smiles`

**Jeu B (1073) â€” alignÃ© en interne**
- `scaffold_split.json` : `train=859`, `test=214`, `index_max=1072`
- `cluster_split_t06.json` : `train=858`, `test=215`
- `cluster_split_t07.json` : `train=858`, `test=215`
- `ad_nn_similarity.npy` : `215` valeurs *(moy=0.686, std=0.135)*
- `ad_stats.json` : `q05=0.411`, `q50=0.693`, `q95=0.870`, seuil recommandÃ© `0.30`
- `duplicates_report.csv` : `1073` lignes, `7` groupes `xhash` dupliquÃ©s, taille max `3`

**Conclusion dâ€™Ã©tat**
- `splits/`, AD et `duplicates` correspondent Ã  **B=1073**.
- `X/Y/dataset_info/CSV` correspondent Ã  **A=1634**.

---

### âœ… DÃ©cision
- **Option retenue** : **B (1073)** pour lot verrouillÃ©, traÃ§able, avec splits/AD/duplicates prÃªts.
- **Garde-fou** : `LOCK_B_1073=1` pour assert de taille.

---

### ğŸ› ï¸ Plan dâ€™action (B=1073)
1. ExÃ©cuter `prepare_dataset()` avec `LOCK_B_1073=1` sur le lot B.
2. **RÃ©gÃ©nÃ©rer et Ã©craser** sur 1073 :  
   - `X_features.npy`, `y_labels*.npy`, `y_reg.npy`, `dataset_info.pkl`, `chembl_dataset_full.*`
3. **Conserver** (dÃ©jÃ  cohÃ©rents B) :  
   - `splits/`, `ad_stats.json`, `ad_nn_similarity.npy`, `duplicates_report.csv`
4. **Exporter** CSV/Parquet **avec** `inchikey` et `standard_smiles` (script corrigÃ©).
5. **Optionnel** : archiver les versions non alignÃ©es en `*_raw_*` (gÃ©rÃ© par le code).

---

### â†©ï¸ Alternative (si A=1634 Ã©tait retenu)
- Recalculer `scaffold_split.json`, `cluster_split_t06.json`, `cluster_split_t07.json` sur 1634.
- Recalculer `ad_nn_similarity.npy` et `ad_stats.json` sur 1634 (split scaffold).
- Refaire `duplicates_report.csv` et vÃ©rifier **0 fuite xhash** train/test.
- RÃ©Ã©crire `dataset_info.pkl` (hash splits, AD, feature_names, versionsâ€¦).
- RÃ©Ã©crire `chembl_dataset_full.csv/parquet` avec `inchikey`/`standard_smiles`.

---

### âœï¸ Changements de code (dÃ©jÃ  intÃ©grÃ©s)
- `LOCK_B_1073` pour verrouillage de taille sur B.
- Export `inchikey`/`standard_smiles` dans CSV/Parquet.
- Anti-fuite `xhash` dans les splits + rapport de doublons.
- AD (NN Tanimoto) + exports `ad_nn_similarity.npy` / `ad_stats.json`.
- `dataset_info.pkl` enrichi (hash splits/AD, densitÃ© Morgan, versionsâ€¦).

---

### ğŸ§ª Check dâ€™intÃ©gritÃ© (rapide)
- **A (1634)** : X/Y/info/CSV **cohÃ©rents**, mais CSV **sans identifiants** et **pas** de splits/AD/duplicates correspondants.
- **B (1073)** : splits/AD/duplicates **OK, sans fuite** ; **manquent** X/Y/info/CSV recalculÃ©s sur 1073.

---

### ğŸ“ Structure attendue aprÃ¨s alignement B

```
data/
â”œâ”€â”€ X_features.npy # (1073, 2054)
â”œâ”€â”€ y_labels.npy # (1073,)
â”œâ”€â”€ y_labels_3class.npy # (1073,)
â”œâ”€â”€ y_reg.npy # (1073,)
â”œâ”€â”€ dataset_info.pkl # meta enrichies (hash, AD, versionsâ€¦)
â”œâ”€â”€ chembl_dataset_full.csv # avec inchikey/standard_smiles
â”œâ”€â”€ chembl_dataset_full.parquet # idem
â”œâ”€â”€ splits/
â”‚ â”œâ”€â”€ scaffold_split.json
â”‚ â”œâ”€â”€ cluster_split_t06.json
â”‚ â””â”€â”€ cluster_split_t07.json
â”œâ”€â”€ ad_stats.json
â”œâ”€â”€ ad_nn_similarity.npy
â””â”€â”€ duplicates_report.csv
```

---

### ğŸš€ Prochaines Ã©tapes
- Lancer `prepare_dataset()` avec `LOCK_B_1073=1`.
- Committer les artefacts et **tagger** : `dataset_COX2_B_1073_r1`.

---

*DerniÃ¨re mise Ã  jour : 2025-09-16*